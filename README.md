# Data ETL Pipeline

A modular **ETL (Extract, Transform, Load)** project for processing carts data from a Dummy API into a SQL Server database using Python.  
The project includes structured logging,configurable database connectivity.

---

## Overview

This ETL pipeline automates the process of reading data from API, cleaning and transforming it, and loading it into a SQL Server table named **`Carts`**.

The process follows a simple 3-step design:

1. **Extract** â€” Reads raw sales data from Excel files.  
2. **Transform** â€” Cleans, validates, and formats data.  
3. **Load** â€” Loads transformed data into SQL Server.  

Comprehensive logging ensures each stage of the ETL process is traceable and auditable.

---

## ğŸ“ Project Structure

### Sales_python_project

- **config.py** â€” Configuration file (database connection, file paths)
- **extract.py** â€” Extracts data from Excel
- **transform.py** â€” Transforms/cleans the extracted data
- **load.py** â€” Loads data into SQL Server
- **logger_config.py** â€” Logger setup for consistent logging
- **main.py** â€” Main ETL execution script
- **README.md** â€” Project documentation
